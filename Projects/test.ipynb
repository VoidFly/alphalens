{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit (conda)",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "26cf43c1c608c90a0ea05d903a93e2015a33d4ebcbaa8dbe110fe807f4a9c975"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphalens\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 814 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_factor=pd.read_csv('./data/my_factor.csv',dtype={'asset':str})\n",
    "#multiIndex [date,asset]\n",
    "my_factor['date']=pd.to_datetime(my_factor['date'])\n",
    "my_factor=my_factor.set_index(['date','asset'])\n",
    "pricing=pd.read_csv('./data/pricing.csv')\n",
    "pricing['date']=pd.to_datetime(pricing['date'])\n",
    "pricing=pricing.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Int64Index([0, 1, 2, 3, 4, 0, 1, 2, 3, 4,\n            ...\n            4, 0, 1, 2, 4, 0, 1, 2, 3, 4],\n           dtype='int64', name='date', length=1164)\n"
     ]
    }
   ],
   "source": [
    "print(my_factor.index.levels[0].dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=my_factor.index.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "get_value() missing 1 required positional argument: 'key'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-db5a771bcf23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: get_value() missing 1 required positional argument: 'key'"
     ]
    }
   ],
   "source": [
    "t.get_value(t,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            000001  000002  000004  000005  000007  000008  000009  000010  \\\n",
       "date                                                                         \n",
       "2016-01-04   11.33   24.43   41.31    9.04   23.79   10.61   16.16    9.10   \n",
       "2016-01-05   11.40   24.43   38.68    8.90   23.79   10.81   15.40    8.59   \n",
       "2016-01-06   11.53   24.43   39.18    9.18   23.79   10.96   15.96    8.94   \n",
       "2016-01-07   10.94   24.43   35.26    8.27   23.79    9.99   14.36    8.05   \n",
       "2016-01-08   11.12   24.43   35.48    8.30   23.79    9.97   14.50    8.06   \n",
       "\n",
       "            000011  000012  ...  603989  603990  603991  603992  603993  \\\n",
       "date                        ...                                           \n",
       "2016-01-04   13.07   12.02  ...   32.21     NaN     NaN     NaN    4.02   \n",
       "2016-01-05   12.52   11.68  ...   30.79     NaN     NaN     NaN    3.94   \n",
       "2016-01-06   12.80   12.04  ...   31.80     NaN     NaN     NaN    4.33   \n",
       "2016-01-07   11.52   10.84  ...   28.62     NaN     NaN     NaN    3.90   \n",
       "2016-01-08   11.60   10.95  ...   29.31     NaN     NaN     NaN    4.09   \n",
       "\n",
       "            603995  603996  603997  603998  603999  \n",
       "date                                                \n",
       "2016-01-04     NaN   32.49   24.31   45.93   63.14  \n",
       "2016-01-05     NaN   35.74   22.47   43.06   69.45  \n",
       "2016-01-06     NaN   39.31   23.31   44.15   76.40  \n",
       "2016-01-07     NaN   43.24   20.98   40.03   68.77  \n",
       "2016-01-08     NaN   47.56   20.93   39.59   62.03  \n",
       "\n",
       "[5 rows x 3601 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>000001</th>\n      <th>000002</th>\n      <th>000004</th>\n      <th>000005</th>\n      <th>000007</th>\n      <th>000008</th>\n      <th>000009</th>\n      <th>000010</th>\n      <th>000011</th>\n      <th>000012</th>\n      <th>...</th>\n      <th>603989</th>\n      <th>603990</th>\n      <th>603991</th>\n      <th>603992</th>\n      <th>603993</th>\n      <th>603995</th>\n      <th>603996</th>\n      <th>603997</th>\n      <th>603998</th>\n      <th>603999</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2016-01-04</th>\n      <td>11.33</td>\n      <td>24.43</td>\n      <td>41.31</td>\n      <td>9.04</td>\n      <td>23.79</td>\n      <td>10.61</td>\n      <td>16.16</td>\n      <td>9.10</td>\n      <td>13.07</td>\n      <td>12.02</td>\n      <td>...</td>\n      <td>32.21</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.02</td>\n      <td>NaN</td>\n      <td>32.49</td>\n      <td>24.31</td>\n      <td>45.93</td>\n      <td>63.14</td>\n    </tr>\n    <tr>\n      <th>2016-01-05</th>\n      <td>11.40</td>\n      <td>24.43</td>\n      <td>38.68</td>\n      <td>8.90</td>\n      <td>23.79</td>\n      <td>10.81</td>\n      <td>15.40</td>\n      <td>8.59</td>\n      <td>12.52</td>\n      <td>11.68</td>\n      <td>...</td>\n      <td>30.79</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.94</td>\n      <td>NaN</td>\n      <td>35.74</td>\n      <td>22.47</td>\n      <td>43.06</td>\n      <td>69.45</td>\n    </tr>\n    <tr>\n      <th>2016-01-06</th>\n      <td>11.53</td>\n      <td>24.43</td>\n      <td>39.18</td>\n      <td>9.18</td>\n      <td>23.79</td>\n      <td>10.96</td>\n      <td>15.96</td>\n      <td>8.94</td>\n      <td>12.80</td>\n      <td>12.04</td>\n      <td>...</td>\n      <td>31.80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.33</td>\n      <td>NaN</td>\n      <td>39.31</td>\n      <td>23.31</td>\n      <td>44.15</td>\n      <td>76.40</td>\n    </tr>\n    <tr>\n      <th>2016-01-07</th>\n      <td>10.94</td>\n      <td>24.43</td>\n      <td>35.26</td>\n      <td>8.27</td>\n      <td>23.79</td>\n      <td>9.99</td>\n      <td>14.36</td>\n      <td>8.05</td>\n      <td>11.52</td>\n      <td>10.84</td>\n      <td>...</td>\n      <td>28.62</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.90</td>\n      <td>NaN</td>\n      <td>43.24</td>\n      <td>20.98</td>\n      <td>40.03</td>\n      <td>68.77</td>\n    </tr>\n    <tr>\n      <th>2016-01-08</th>\n      <td>11.12</td>\n      <td>24.43</td>\n      <td>35.48</td>\n      <td>8.30</td>\n      <td>23.79</td>\n      <td>9.97</td>\n      <td>14.50</td>\n      <td>8.06</td>\n      <td>11.60</td>\n      <td>10.95</td>\n      <td>...</td>\n      <td>29.31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.09</td>\n      <td>NaN</td>\n      <td>47.56</td>\n      <td>20.93</td>\n      <td>39.59</td>\n      <td>62.03</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 3601 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "pricing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dropped 100.0% entries from factor data: 100.0% in forward returns computation and 0.0% in binning phase (set max_loss=0 to see potentially suppressed Exceptions).\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "MaxLossExceededError",
     "evalue": "max_loss (35.0%) exceeded 100.0%, consider increasing it.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMaxLossExceededError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-6112177ca527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Ingest and format data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m factor_data = alphalens.utils.get_clean_factor_and_forward_returns(my_factor,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                                    \u001b[0mpricing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                    \u001b[0mgroupby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Projects\\alphalens\\alphalens\\utils.py\u001b[0m in \u001b[0;36mget_clean_factor_and_forward_returns\u001b[1;34m(factor, prices, groupby, binning_by_group, quantiles, bins, periods, filter_zscore, groupby_labels, max_loss, zero_aware, cumulative_returns)\u001b[0m\n\u001b[0;32m    834\u001b[0m     )\n\u001b[0;32m    835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 836\u001b[1;33m     factor_data = get_clean_factor(factor, forward_returns, groupby=groupby,\n\u001b[0m\u001b[0;32m    837\u001b[0m                                    \u001b[0mgroupby_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroupby_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m                                    \u001b[0mquantiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquantiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Projects\\alphalens\\alphalens\\utils.py\u001b[0m in \u001b[0;36mget_clean_factor\u001b[1;34m(factor, forward_returns, groupby, binning_by_group, quantiles, bins, groupby_labels, max_loss, zero_aware)\u001b[0m\n\u001b[0;32m    658\u001b[0m         message = (\"max_loss (%.1f%%) exceeded %.1f%%, consider increasing it.\"\n\u001b[0;32m    659\u001b[0m                    % (max_loss * 100, tot_loss * 100))\n\u001b[1;32m--> 660\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mMaxLossExceededError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_loss is %.1f%%, not exceeded: OK!\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxLossExceededError\u001b[0m: max_loss (35.0%) exceeded 100.0%, consider increasing it."
     ]
    }
   ],
   "source": [
    "# Ingest and format data\n",
    "factor_data = alphalens.utils.get_clean_factor_and_forward_returns(my_factor,\n",
    "                                                                   pricing,\n",
    "                                                                   \n",
    "                                                                   groupby=None,\n",
    "                                                                   groupby_labels=None\n",
    "                                                                   )#quantiles=5,\n",
    "# Run analysis\n",
    "#alphalens.tears.create_full_tear_sheet(factor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "np.concatenate(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "np.array([True,True,False]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    2.200\n",
       "1    2.640\n",
       "2    3.432\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "import empyrical as ep\n",
    "s=pd.Series([0.1,0.2,0.3])\n",
    "ep.cum_returns(s,starting_value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcum_returns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstarting_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Compute cumulative returns from simple returns.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "returns : pd.Series, np.ndarray, or pd.DataFrame\n",
      "    Returns of the strategy as a percentage, noncumulative.\n",
      "     - Time series with decimal returns.\n",
      "     - Example::\n",
      "\n",
      "        2015-07-16   -0.012143\n",
      "        2015-07-17    0.045350\n",
      "        2015-07-20    0.030957\n",
      "        2015-07-21    0.004902\n",
      "\n",
      "     - Also accepts two dimensional data. In this case, each column is\n",
      "       cumulated.\n",
      "\n",
      "starting_value : float, optional\n",
      "   The starting returns.\n",
      "out : array-like, optional\n",
      "    Array to use as output buffer.\n",
      "    If not passed, a new array will be created.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "cumulative_returns : array-like\n",
      "    Series of cumulative returns.\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\50257\\anaconda3\\lib\\site-packages\\empyrical\\stats.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "?ep.cum_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2, 3, 5, 5]"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "a=[5,3,2,5]\n",
    "sorted(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "set([1,2,3])-set([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}